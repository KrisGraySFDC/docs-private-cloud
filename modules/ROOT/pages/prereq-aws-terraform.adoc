= Create Anypoint Private Cloud Resources on Amazon Web Services (AWS)
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]

This topic describes how to create the resources required to install Anypoint Platform Private Cloud Edition on Amazon Web Services (AWS). Anypoint Private Cloud supports 3-node and 6-node configurations in a production environment on AWS.

== Prerequisites

To install Anypoint Platform Private Cloud Edition on AWS, you must have an AWS account with the following:

* Your account must have AWS keys with EC2FullAccess and S3FullAccess permissions.
* When creating your AWS environment, the following resources are created:
+
[%header%autowidth.spread]
|===
| AWS Resource | Number required (3-node) | Number required (6-node)
| m4.2xlarge | 3 | 6
| root disk @ 500 iops | 3 | 6
| EBS volumes @ 1500 iops | 6 | 12
| EBS volume @ 3000 iops | 6 | 12
| Amazon ELB | 1 | 1
| t2.medium | 1 | 1
|===

== Run the AWS Provisioner

MuleSoft provides a Docker image that you can use to provision the resources for your AWS account.

. Create an initial instance (t2.small) on your AWS account on any VPC with internet access.
+
This instance is used to run the actual provisioning of the cluster. You must use an AMI that has Docker installed by default or you must manually install Docker after creating the AWS instance.
+
You can also run provisioner remotely from any other machine with Docker and internet access.

. Download the provisioner Docker image from the following URL:
+
----
https://onprem-standalone-installers.s3.amazonaws.com/pce-2.0-provisioner.tar.gz?Signature=jYdE6HCDAzwLS6c3bQjua6v0ldE%3D&Expires=1694920896&AWSAccessKeyId=AKIAI3RYALJL3PWNBRSQ
----

Copy the provisioner Docker image to the instance via SCP

----
scp -i <guest>.pem ~/Downloads/pce-2.0-aws-provisioner.gz ec2-user@18.221.155.87:/home/ec2-user
----

. SSH into the instance
+
----
ssh -i 'anypoint.pem' ec2-user@18.221.155.87
----

. Create the var file (pce.env) with the environment details using the template below:

[%header%autowidth.spread]
|===
| Name | Description
| AWS_ACCESS_KEY_ID | Specifies the AWS access ID Terraform uses to connect to your AWS account
| AWS_SECRET_ACCESS_KEY | Specifies the AWS access key Terraform uses to connect to your AWS account
| AWS_KEY_NAME | Specifies the AWS SSH key. Do not include the .pem extension.
| AWS_REGION | Specifies the AWS region where Terraform creates the cluster. For example: `us-east-2`. Must have the same value as AWS_DEFAULT_REGION.
| AWS_DEFAULT_REGION | Same as above. Must have the same value as AWS_REGION
| TF_VAR_ssh_user=<SSH_USER> | Specifies the ssh user. For example: `ec2-user`, `centos`, etc)
| CLOUD_PROVIDER | Must be `aws`
| CLUSTER_TYPE | Must be `pce`
| TELEKUBE_CLUSTER_NAME | Specifies the name of the cluster and the corresponding AWS resources
| TELEKUBE_NODE_PROFILE_COUNT_node | Specifies the number of nodes in your cluster. Possible values are `3`, and `6`
| TELEKUBE_NODE_PROFILE_INSTANCE_TYPE_node | Must be `m4.4xlarge`
| TELEKUBE_NODE_PROFILES | Must be set to `node`
| TF_VAR_high_performance_disks | Must be set to `true` for production environments
|===

You can also include the following set of optional environment variables:

[%header%autowidth.spread]
|===
| Name | Description
| TF_VAR_ami_name | Enables you to specify the name of the AMI to be used for the instances. Use the AMI name and NOT the AMI Id. If you do not set this variable, the provisioner uses the folowing AMI by default: `RHEL-7.4_HVM_GA-20170808-x86_64-2-Hourly2-GP2`
| TF_VAR_monitoring=<true or false> | If true it will create basic instance alarms in Cloudwatch.
| TF_VAR_use_bastion=<true or false> | If true it will create a small instance (using an ASG) in a public subnet as a jumpbox and associate a public IP address, and launch the cluster instances in the private subnets
| TF_VAR_internal=<true or false> | If true the cluster instances will be launched in private subnets and will not have public ips associated with them. Also, the provisioned load balancer will be internal only
| AWS_VPC_ID=<VPC_ID> | Specifies an existing VPC. It should already have an internet gateway attached to it. Subnets will still be provisioned within the existing VPC
| AWS_VPC_CIDR=<VPC_CIDR> | You can pass a preferred CIDR for the new VPC that will be provisioned. (Requires not to pass a VPC_ID)
| TF_VAR_subnets=<PRIVATE_SUBNETS_CIDRs> | You can pass the preferred CIDRs blocks for the new subnets that will be provisioned. You must pass exactly the minimum num	ber between the number of AZs of the region and the number of nodes you selected for your cluster. For example: `'["10.1.0.0/24", "10.1.1.0/24", "10.1.2.0/24"]'`
| TF_VAR_public_subnets=<PUBLIC_SUBNETS_CIDRs> | You can pass the preferred CIDRs blocks for the new subnets that will be provisioned. You must pass exactly the minimum num	ber between the number of AZs of the region and the number of nodes you selected for your cluster. For example: `'["10.1.3.0/24", "10.1.4.0/24", "10.1.5.0/24"]'`
| TF_VAR_role_tag_value=<AWS_TAG_VALUE_FOR_ROLE_LABEL> | You can provide a value for a ROLE tag that all AWS resources will have
|===

. Load the provisioner Docker image into the local Docker registry:
+
----
docker load -i pce2.0-aws-provisioner.gz
----

. Record the image ID after running the `docker load` command. This is required in the following step.

.  (Optional) Perform a dry-run
+
----
docker run --rm --env-file pce.env IMAGE_ID dry-run
----
+

.  Run the provisioner
+
----
docker run --rm --env-file pce.env IMAGE_ID cluster-provision
----
+
After the provisioner runs successfully, it displays information about your environment including IP addresses, DNS name of the load balancer, etc.

. Verify that the provisioning script ran successfully by checking the existence of /var/lib/bootstrap_complete on the instances

== Open Port 61009 Before Installation (Optional)

If you are installing Anypoint Private Cloud Edition using the GUI-based installer, you must enable this port before running the installer. You must open this port to the world in the cluster's security group before running the installer using AWS Web Console.

== Install Anypoint Platform Private Cloud Edition

After provisioning resources in your AWS environment and uploading the installer to one of the nodes, install Anypoint Platform Private Cloud Edition using one of the installers:

* xref:install-installer.adoc[To Install Anypoint Private Cloud using the GUI Installer]
* xref:install-auto-install.adoc[To Install Anypoint Private Cloud using the Command Line Installer]

== Disabling Port 61009 After Installation

After installation is finished you can close port 61009 in the cluster security group using the AWS Web console.

== Troubleshooting

* 403 Forbidden

Check that your keys policies are not denying access to any EC2 or S3 resource. You should be able to run the following basic command using AWS CLI with your keys:

----
aws sts get-caller-identity
----

* Limit excedded

The AWS account might have some limits set on the amount of the resources you can create. Delete some unused resources or request a limit increason from AWS.

* AMI not found

Make sure you are using the AMI name as the value for the environment variable and not the ID.

== See Also

* https://www.terraform.io/intro/getting-started/install.html[Install Terraform]
* https://docs.aws.amazon.com/quickstart/latest/linux-bastion/welcome.html[Linux Bastion Hosts on the AWS Cloud: Quick Start Reference Deployment]
